"""
Dual-TTS helper:
- Nháº­n text input
- TÃ¡ch cÃ¡c cá»¥m tá»« tiáº¿ng Anh
- Gá»i VieNeu-TTS Ä‘á»ƒ tá»•ng há»£p pháº§n tiáº¿ng Viá»‡t
- Gá»i viXTTS (Coqui TTS via `TTS` lib) Ä‘á»ƒ tá»•ng há»£p pháº§n tiáº¿ng Anh
- GhÃ©p wave (numpy) vÃ  tráº£ vá» numpy array + samplerate
"""

import re
import numpy as np
import soundfile as sf
import tempfile
import os
from typing import Tuple

# Try to import TTS (viXTTS). If khÃ´ng cÃ³, chÃºng ta mock Ä‘á»ƒ dev.
try:
    from TTS.api import TTS as CoquiTTS
    HAVE_COQUI = True
except Exception:
    HAVE_COQUI = False

# Regex Ä‘Æ¡n giáº£n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tá»«/chuá»—i tiáº¿ng Anh (latin letters)
ENG_TOKEN_RE = re.compile(r"[A-Za-z0-9\-\']+")

def split_text_segments(text: str):
    """
    Tráº£ vá» list cá»§a (lang, token) theo thá»© tá»± xuáº¥t hiá»‡n,
    lang: 'vi' hoáº·c 'en'
    Simple: group contiguous english tokens as en, others as vi.
    """
    tokens = text.split()
    segments = []
    cur_lang = None
    cur_words = []
    for w in tokens:
        if ENG_TOKEN_RE.fullmatch(w):
            lang = "en"
        else:
            lang = "vi"
        if cur_lang is None:
            cur_lang = lang
            cur_words = [w]
        elif lang == cur_lang:
            cur_words.append(w)
        else:
            segments.append((cur_lang, " ".join(cur_words)))
            cur_lang = lang
            cur_words = [w]
    if cur_lang is not None:
        segments.append((cur_lang, " ".join(cur_words)))
    return segments

def concat_audio_segments(segments_wavs, target_sr=24000, gap_s=0.05):
    """
    segments_wavs: list of numpy arrays (mono)
    target_sr: sample rate
    gap_s: silence gap between segments (seconds)
    Return: numpy float32 array
    """
    gap = np.zeros(int(gap_s * target_sr), dtype=np.float32)
    out = []
    for i, w in enumerate(segments_wavs):
        # ensure float32
        arr = w.astype(np.float32)
        # if stereo, convert to mono
        if arr.ndim == 2:
            arr = arr.mean(axis=1)
        out.append(arr)
        if i != len(segments_wavs) - 1:
            out.append(gap)
    if not out:
        return np.zeros(0, dtype=np.float32)
    return np.concatenate(out)

class DualTTS:
    def __init__(self, vieneu_tts, vixtts_model_name: str = "tts_models/en/vctk/vits"):
        """
        vieneu_tts: instance of your VieNeuTTS (or compatible) with methods:
           - encode_reference(path) -> ref_codes
           - infer(text, ref_codes, ref_text_raw) -> numpy waveform (float32) at 24000
        vixtts_model_name: coqui TTS model name to use for English (can change)
        """
        self.vieneu = vieneu_tts
        self.target_sr = 24000
        self.vixtts = None
        if HAVE_COQUI:
            try:
                # Táº£i model viXTTS / Coqui TTS (English)
                self.vixtts = CoquiTTS(model_name=vixtts_model_name)
            except Exception as e:
                print("âš ï¸ KhÃ´ng táº£i Ä‘Æ°á»£c Coqui TTS model:", e)
                self.vixtts = None
        else:
            print("âš ï¸ Coqui TTS (TTS lib) khÃ´ng cÃ i Ä‘áº·t. English TTS sáº½ bá»‹ mock.")

    def synthesize_segment_vn(self, text_vn: str, ref_audio_path: str, ref_text_raw: str):
        """
        Gá»i VieNeu TTS Ä‘á»ƒ tá»•ng há»£p pháº§n tiáº¿ng Viá»‡t - tráº£ vá» numpy waveform float32
        """
        ref_codes = None
        try:
            ref_codes = self.vieneu.encode_reference(ref_audio_path)
        except Exception as e:
            print("âš ï¸ Lá»—i khi encode_reference:", e)
        wav = self.vieneu.infer(text_vn, ref_codes, ref_text_raw)
        # Ä‘áº£m báº£o float32 numpy
        arr = np.array(wav, dtype=np.float32)
        return arr

    def synthesize_segment_en(self, text_en: str):
        """
        Gá»i viXTTS/Coqui TTS Ä‘á»ƒ tá»•ng há»£p English; náº¿u khÃ´ng cÃ³ Coqui TTS,
        sáº½ tráº£ vá» máº£ng Ã¢m rá»—ng.
        """
        if not text_en or text_en.strip() == "":
            return np.zeros(0, dtype=np.float32)
        if self.vixtts is None:
            # Mock: phÃ¡t ra silence trong 0.5s x sá»‘ tá»« (fallback development)
            n_words = len(text_en.split())
            dur = max(0.25, 0.12 * n_words)
            print(f"âš ï¸ ViXTTS khÃ´ng sáºµn sÃ ng â€” tráº£ vá» silence {dur}s cho {[text_en]}")
            return np.zeros(int(dur * self.target_sr), dtype=np.float32)
        # Coqui TTS tráº£ vá» wav numpy & sr (tuá»³ model); TTS.api.TTS.tts_to_file hoáº·c tts_to_numpy
        try:
            # tts_to_file tÆ°Æ¡ng thÃ­ch nhÆ°ng Ä‘á»ƒ láº¥y numpy dÃ¹ng tts.tts
            wav = self.vixtts.tts(text_en)
            # Coqui TTS tts() cÃ³ thá»ƒ tráº£ vá» numpy array hoáº·c filepath; handle both
            if isinstance(wav, str) and os.path.exists(wav):
                arr, sr = sf.read(wav)
                if sr != self.target_sr:
                    # resample if needed (try simple np.repeat/decimate if integer ratio)
                    import math
                    ratio = self.target_sr / sr
                    arr = np.interp(
                        np.arange(0, len(arr) * ratio) / ratio,
                        np.arange(0, len(arr)),
                        arr
                    ).astype(np.float32)
                return arr.astype(np.float32)
            elif isinstance(wav, np.ndarray):
                return wav.astype(np.float32)
            else:
                return np.array(wav, dtype=np.float32)
        except Exception as e:
            print("âš ï¸ Lá»—i khi synthesize EN with viXTTS:", e)
            return np.zeros(0, dtype=np.float32)

    def synthesize_dual(self, full_text: str, ref_audio_path: str, ref_text_raw: str) -> Tuple[np.ndarray, int]:
        """
        Main: tÃ¡ch chuá»—i, synth má»—i Ä‘oáº¡n phÃ¹ há»£p, ghÃ©p láº¡i.
        Tráº£ vá» (wav_array (float32), samplerate)
        """
        segments = split_text_segments(full_text)
        wav_segments = []
        for lang, seg_text in segments:
            if lang == "vi":
                if seg_text.strip():
                    print("ğŸ”Š Synth VN segment:", seg_text)
                    wav_vn = self.synthesize_segment_vn(seg_text, ref_audio_path, ref_text_raw)
                    wav_segments.append(wav_vn)
            else:  # en
                if seg_text.strip():
                    print("ğŸ”Š Synth EN segment:", seg_text)
                    wav_en = self.synthesize_segment_en(seg_text)
                    wav_segments.append(wav_en)
        out = concat_audio_segments(wav_segments, target_sr=self.target_sr, gap_s=0.06)
        return out, self.target_sr

# Convenience factory
def make_dual_tts(vieneu_tts, vixtts_model_name="tts_models/en/vctk/vits"):
    return DualTTS(vieneu_tts, vixtts_model_name=vixtts_model_name)
